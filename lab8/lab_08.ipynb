{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195360da-9f12-47bf-8867-216253d85a6b",
   "metadata": {},
   "source": [
    "## Zad 1.\n",
    "Napisz program, który wykorzystuje metodę `Importance Sampling` do oszacowania wartości całki:\n",
    "$$\n",
    "\\int^1_0 \\cos\\left(\\frac{\\pi x}{2}\\right) dx = \\frac{2}{\\pi}.\n",
    "$$\n",
    "\n",
    "Jako rozkład ważności użyj rozkładu `Beta(a, 1)`, którego gęstość wynosi $g(x) = ax^{a-1}$ dla $x\\in[0, 1]$. Oblicz estymator Importance Sampling:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{i=1}^N\\frac{f(x_i)}{g(x_i)},\n",
    "$$\n",
    "gdzie $x_i$ są próbkami z rozkładu $g(x)$. Porównaj wyniki dla różnych rozmiarów próbek ($N = 100, 1000, 10000$), przedstaw błąd względny w porównaniu z wartością dokładną. Dodatkowo, porównaj wyniki z metodą `Monte Carlo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6236914-972b-4077-9f54-191a8341c9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f876280a-20c5-46e6-8709-51ec6d8ba55a",
   "metadata": {},
   "source": [
    "### Zad 2.\n",
    "Korzystając z kodów dostępnych na [stronie](https://github.com/timbmg/VAE-CVAE-MNIST/tree/master) wytrenuj modele `Variational Autoencoder (VAE)` i `Conditional Variational Autoenoder (cVAE)` na zbiorze `MNIST`. Następnie wygeneruj dużą próbkę obrazów z wytrenowanych modeli i porównaj ich wartości `FID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb99f4b-695c-4079-bd85-d8de94cc81e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60530267-d488-4d3c-a280-d2cc1c712e04",
   "metadata": {},
   "source": [
    "### Zad 3.\n",
    "Bazując na oficjalnym [tutorialu PyTorch dotyczącym DCGAN](https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html), wytrenuj model `DCGAN` na zbiorze `MNIST`. Po zakończeniu treningu wygeneruj 10 000 próbek z modelu, a następnie oblicz wartość metryki `FID` dla uzyskanej próbki, aby ocenić jakość generowanych obrazów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668bef2-5b19-4032-a861-644c8ecb3f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b4b1a0e-9148-4a15-acb6-2435ec10a0bf",
   "metadata": {},
   "source": [
    "### Zad 4.\n",
    "Korzystając z implementacji modeli [WGAN-CP (Wasserstein GAN oparty na przycinaniu wag) oraz WGAN-GP (Wasserstein GAN z karą gradientową)](https://github.com/Zeleni9/pytorch-wgan/tree/master), przeprowadź trening obu modeli na zbiorze [Fashion-MNIST](https://en.wikipedia.org/wiki/Fashion-MNIST). Następnie wygeneruj obrazy z wytrenowanych sieci, porównaj jakość rezultatów oraz omów różnice między modelami, uwzględniając stabilność treningu i efektywność generowania próbek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5927d49-4614-46db-b3a6-a01952a18ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
