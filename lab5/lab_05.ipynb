{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195360da-9f12-47bf-8867-216253d85a6b",
   "metadata": {},
   "source": [
    "## Zad 1.\n",
    "Napisz funkcję liczącą \n",
    "$$\n",
    "\\mathrm{MMD}^2_k(X,Y) = \\frac{1}{n^2} \\sum_{i, j} k(x_i, x_j) + \\frac{1}{m^2} \\sum_{i, j} k(y_i, y_j) - \\frac{2}{nm} \\sum_{i,j} k(x_i, y_j),\n",
    "$$\n",
    "gdzie $x_i\\in X$, $y_i\\in Y$, zaś $k(\\cdot, \\cdot)$ jest kernelem. Wygeneruj dwie próbki z rozkładu normalnego w $\\mathbf{R}^2$ o różnych parametrach i policz dla tych próbek metrykę $\\mathrm{MMD}$. Użyj 3 różnych kerneli:\n",
    "- jądro Gaussa (RBF),\n",
    "- jądro Laplace’a,\n",
    "- jądro Cauchy’ego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88b898-1530-476c-a208-846afd25f9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41bd6fc7-fa80-4e15-9579-b2f9b2ab2045",
   "metadata": {},
   "source": [
    "### Zad 2.\n",
    "Rozważmy proces Gaussowski z funkcją średniej $m(x)$ i jądrem $k(x, x')$:\n",
    "$$\n",
    "f \\sim \\mathcal{GP}(m(x), k(x, x'))\n",
    "$$\n",
    "oraz zbiór obserwacji $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^n$, gdzie:\n",
    "$$\n",
    "y_i = f(x_i) + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)\n",
    "$$\n",
    "czyli obserwacje są zaburzone niezależnym szumem Gaussowskim o wariancji $\\sigma_n^2$.\n",
    "\n",
    "\n",
    "Dla danych treningowych $X = [x_1, \\ldots, x_n]^T$ i $y = [y_1, \\ldots, y_n]^T$ wykonaj poniższe zadania:\n",
    "- zaimplementować bezpośrednie obliczenia predykcji procesu Gaussowskiego używając formuł analitycznych,\n",
    "- porównać wyniki z implementacją `GaussianProcessRegressor` z biblioteki `scikit-learn`,\n",
    "- zwizualizować wyniki predykcji wraz z przedziałami ufności.\n",
    "\n",
    "Użyj przynajmniej dwóch różnych kerneli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b0b41-6cad-43c7-b5b2-395cb079c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "# Generowanie danych syntetycznych\n",
    "np.random.seed(124)\n",
    "n_train = 50\n",
    "n_test = 200\n",
    "\n",
    "# Funkcja celu\n",
    "def true_function(x):\n",
    "    return np.sin(2 * np.pi * x) + 0.3 * np.cos(4 * np.pi * x)\n",
    "\n",
    "# Dane treningowe\n",
    "X_train = np.random.uniform(0, 1, n_train).reshape(-1, 1)\n",
    "y_train = true_function(X_train).ravel() + np.random.normal(0, 0.1, n_train)\n",
    "\n",
    "# Dane testowe\n",
    "X_test = np.linspace(-0.2, 1.2, n_test).reshape(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42939e-de2e-4bc6-880a-d87ad62db138",
   "metadata": {},
   "source": [
    "# Nienadzorowana reprezentacja danych - AutoEnkoder (AE)\n",
    "\n",
    "Prosta implementacja PCA za pomocą warstwy liniowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2ff6a-17e4-4504-9341-8b6e42ca98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mnist = load_digits(n_class=10)\n",
    "x, y = mnist.data, mnist.target\n",
    "\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "v = pca.transform(x[:10])\n",
    "x_reduced = np.dot(x[:10] - pca.mean_, pca.components_.T)\n",
    "assert np.allclose(v, x_reduced)\n",
    "\n",
    "x_original = np.dot(x_reduced, pca.components_) + pca.mean_\n",
    "assert np.allclose(pca.inverse_transform(v), x_original)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(*v.T, marker='d', color='b', s=60)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x_original[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b05c5-074e-485f-a0aa-4a0b4c14c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class OwnPCA():\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Linear(input_dim, output_dim, bias=False)\n",
    "        self.dencoder = torch.nn.Linear(output_dim, input_dim, bias=False)\n",
    "        \n",
    "    def set_weight(self, W):\n",
    "        self.encoder.weight.data[...] = torch.from_numpy(W)\n",
    "        self.dencoder.weight.data[...] = torch.from_numpy(W.T)\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def inverse_transform(self, x):\n",
    "        return self.dencoder(x)\n",
    "\n",
    "\n",
    "pca_own = OwnPCA(64, 10)\n",
    "pca_own.set_weight(pca.components_)\n",
    "\n",
    "v = pca_own.transform(\n",
    "    torch.from_numpy(\n",
    "        (x[:10] - pca.mean_).astype(np.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "x_ = pca_own.inverse_transform(v).detach().numpy() + pca.mean_\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x_[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f876280a-20c5-46e6-8709-51ec6d8ba55a",
   "metadata": {},
   "source": [
    "### Zad 3.\n",
    "Przeanalizuj powyższy kod i przepisz go tak, aby nie korzystał z biblioteki PyTorch, lecz wyłącznie z numpy. Następnie porównaj uzyskane rezultaty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9b875-e8a4-4543-8518-91cdf101abc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63eeecd2-81b3-493f-b693-3de0f9f1f83d",
   "metadata": {},
   "source": [
    "# Uczenie sieci AE\n",
    "\n",
    "Klasa ,,*AverageMeter*'' przechowuje oraz przetwarza częściowe wyniki zapisywane w poszczegółnych etapach uczenia modelu. Funkcja ,,*count_parameters*'' zlicza liczbę parametrów sieci, zaś funkcja ,,*show*'' rysuje obrazki ze zbioru danych i ich rekonstrukcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a2541-7b59-40da-a890-a12d5c47eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sns.set(font_scale=2.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum = self.sum + val * n\n",
    "        self.count = self.count + n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def show(img, recon_img, num_col=None):\n",
    "    if recon_img is None:\n",
    "        rec_images = img\n",
    "    else:\n",
    "        n = img.shape[0]\n",
    "        assert n >= num_col\n",
    "        rec_images = torch.empty((2 * num_col, *img.shape[1:]))\n",
    "        rec_images.data[:num_col] = img.data[:num_col]\n",
    "        rec_images.data[num_col:] = recon_img.data[:num_col]\n",
    "\n",
    "    plt.figure(figsize=[16, 8])\n",
    "    grid = torchvision.utils.make_grid(\n",
    "        rec_images, nrow=num_col, padding=1, normalize=True, scale_each=True\n",
    "    )\n",
    "    np_grid = grid.cpu().numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)), interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24314854-58a3-4c54-b2f2-ebd797e08e91",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "W tej części przygotowujemy zbiór danych do trenowania i walidacji modelu. Przetwarzamy obrazki ze zbioru *MNIST* do tensorów, które są pobierane iteracyjnie w batchach podczas trenowania sieci (zmienne: ,,*train_loader*'', ,,*test_loader*'')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02a4cd-594a-46b4-80d2-9386241af130",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./datasets\"\n",
    "download = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=True, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=False, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=200, shuffle=False, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "# \n",
    "d = train_dataset[1]\n",
    "print(f\"Rozmiar obrazka: {d[0].shape} oraz jego etykieta {d[1]}\")\n",
    "\n",
    "it = iter(train_loader)\n",
    "d = next(it)\n",
    "d[0].shape, d[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24c949-342b-460f-bfab-4cceaa1f4690",
   "metadata": {},
   "source": [
    "Poniżej tworzymy dodatkowe klasy, których będziemy używać do budowy sieci neuronowej (klasa ,,*View*'') jak również do uczenia jej (klasa ,,*LambdaLR*''). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76630367-8e24-4c80-8d14-163a17ea637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(torch.nn.Module):\n",
    "    def __init__(self, *shape) -> None:\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> torch.Tensor:\n",
    "        return input_x.view(*self.shape)\n",
    "\n",
    "\n",
    "class LambdaLR(torch.optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(\n",
    "        self, optimizer, lr_lambda, last_epoch=-1, verbose=False, min_val=1e-5\n",
    "    ):\n",
    "        self.min_val = min_val\n",
    "        self.change = True\n",
    "\n",
    "        super(LambdaLR, self).__init__(optimizer, lr_lambda, last_epoch, verbose)\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if self.change:\n",
    "            super().step(epoch)\n",
    "\n",
    "            change = False\n",
    "            values = self.get_last_lr()\n",
    "            for i, data in enumerate(zip(self.optimizer.param_groups, values)):\n",
    "                param_group, lr = data\n",
    "                param_group[\"lr\"] = lr if lr > self.min_val else self.min_val\n",
    "                self.print_lr(self.verbose, i, lr, epoch)\n",
    "\n",
    "            self._last_lr = [group[\"lr\"] for group in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5895958-94e5-436a-b9a6-54ed826ef27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Pierwszy wykres - podstawowy LambdaLR\n",
    "model = torch.nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "fun = lambda epoch: 0.9 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=fun, last_epoch=-1)\n",
    "\n",
    "epochs = 300\n",
    "lrs = []\n",
    "for i in range(epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(epochs), lrs)\n",
    "plt.title('LambdaLR scheduler')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Drugi wykres - z minimalną wartością learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Zmodyfikowana funkcja z minimalną wartością\n",
    "def fun_with_min(epoch):\n",
    "    lr = 0.9 ** epoch\n",
    "    return max(lr, 1e-2)  # Minimum 0.01\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=fun_with_min, last_epoch=-1)\n",
    "\n",
    "epochs = 300\n",
    "lrs = []\n",
    "for i in range(epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr()[0])  # get_last_lr() zwraca listę\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(epochs), lrs)\n",
    "plt.title('LambdaLR with minimum learning rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')  # Wykres logarytmiczny dla lepszej czytelności\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60530267-d488-4d3c-a280-d2cc1c712e04",
   "metadata": {},
   "source": [
    "# AutoEncoder\n",
    "\n",
    "Klasa ,,*AE*'' definuje sieć autoenkodera składająca się z dwóch części: kodującej (enkodera) i dekodującej (dekodera). \n",
    "\n",
    "### Zad 4.\n",
    "Napisać klasę `AE`, której części enkoder i dekoder składają się z dwóch warstw fully-connected. Funkcja ,,forward'' powinna zwracać obrazek o rozmiarze (1, 28, 28) w postaci tensora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852031c-e851-465c-8150-39da2e213635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, dim_hidden):\n",
    "        super().__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24728719-a148-451e-9221-b832d787bcae",
   "metadata": {},
   "source": [
    "[Jak działa wartstwa konwolucyjna?](https://bfirst.tech/konwolucyjne-sieci-neuronowe/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf47fa-f4b1-4bd7-a007-be99b3f0990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim: int, dim_hidden: int) -> None:\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_h = dim_hidden\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, self.dim_h, 4, 2, 1, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 2),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 4),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(self.dim_h * (2**3), latent_dim),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, self.dim_h * 8 * 7 * 7),\n",
    "            torch.nn.ReLU(True),\n",
    "            View(-1, self.dim_h * 8, 7, 7),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 4),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 2),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        z = self.encoder(input_x)\n",
    "        return z, self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625fdaa-c0b3-4a05-8027-65930aa139a7",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668bef2-5b19-4032-a861-644c8ecb3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 8\n",
    "dim_hidden = 16\n",
    "\n",
    "model = AE(latent_dim=latent_dim, dim_hidden=dim_hidden)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "use_scheduler = True\n",
    "scheduler = None\n",
    "if use_scheduler:\n",
    "    # LambdaLR nie ma parametru min_val, więc tworzymy własną funkcję\n",
    "    def lr_lambda(epoch):\n",
    "        lr = 0.8 ** epoch\n",
    "        return max(lr, 1e-5)  # Minimalna wartość learning rate 1e-5\n",
    "    \n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "scores = {\"train\": {\"loss\": []}, \"test\": {\"loss\": []}}\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, _ in train_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        _, recon = model(image)\n",
    "        loss = mse_loss(recon, image)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item())\n",
    "\n",
    "        train_tqdm.set_description(f\"TRAIN loss: {losses.val:.4f} ({losses.avg:.4f})\")\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, _ in eval_tqdm:\n",
    "            image = image.to(device)\n",
    "\n",
    "            _, recon = model(image)\n",
    "            loss = mse_loss(recon, image)\n",
    "\n",
    "            losses.update(loss.item())\n",
    "\n",
    "            eval_tqdm.set_description(f\"TEST loss: {losses.val:.4f} ({losses.avg:.4f})\")\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "\n",
    "    # Pobieranie aktualnego learning rate\n",
    "    current_lr = scheduler.get_last_lr()[0] if use_scheduler else optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]; \"\n",
    "        f\"train: {scores['train']['loss'][-1]:.4f}; \"\n",
    "        f\"test: {scores['test']['loss'][-1]:.4f}\"\n",
    "        f\"{f'; lr: {current_lr:.2e}' if use_scheduler else ''}\"\n",
    "    )\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(), \"ae.pth\"\n",
    ")  # zapisujemy model do dalszej ewaluacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384c60b-694a-4884-9ec8-f6c11989c23d",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy zmianę funkcji kosztu sieci AE w trakcie jej uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a6a52-eb7c-48be-9b91-c7e3b31d9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Poprawione kolory i etykiety - spójne z danymi\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"loss\"],\n",
    "    \"r-\",\n",
    "    linewidth=4,\n",
    "    label=\"Loss na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"loss\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    label=\"Loss na zbiorze testowym\",\n",
    ")\n",
    "\n",
    "# Poprawione ustawienia osi\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"major\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    labelsize=12\n",
    ")\n",
    "\n",
    "# Ustawienia siatki\n",
    "ax.grid(True, which=\"both\", alpha=0.5)\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "# Legenda i opisy\n",
    "ax.legend(loc=\"best\", fontsize=14)\n",
    "ax.set_ylabel(\"Loss\", fontsize=14)\n",
    "ax.set_xlabel(\"Epoka\", fontsize=14)\n",
    "ax.set_title(\"Funkcja straty podczas trenowania\", fontsize=16)\n",
    "\n",
    "# Dodanie siatki pomocniczej\n",
    "ax.minorticks_on()\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf2c85-7995-407e-b8c3-700c685e8af5",
   "metadata": {},
   "source": [
    "Czas teraz na pokazanie jak wyuczona sieć AE rekonstruuje obrazki ze zbioru MNIST. W tym celu przepuszczamy przez sieć obrazki ze zbioru walidującego (górny wiersz obrazka), a sieć zwraca ich rekonstrukcje (dolny wiersz obrazka).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a392ed-0ab1-4935-9976-4376960185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating\n",
    "model.eval()\n",
    "\n",
    "mses = AverageMeter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        _, recon = model(image)\n",
    "        loss = mse_loss(recon, image)\n",
    "\n",
    "        mses.update(loss.item())\n",
    "\n",
    "        eval_tqdm.set_description(f\"mse: {mses.val:.4g} ({mses.avg:.4g})\")\n",
    "\n",
    "        if i == len(test_loader) - 1:\n",
    "            show(image, recon, 10)\n",
    "\n",
    "print(f\"Ewaluation MSE: {mses.avg:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e7a20-8e1c-4b63-b308-7a5ada73f21f",
   "metadata": {},
   "source": [
    "### Zad 5.\n",
    "Zmodyfikuj architekturę sieci `AE` używając warstw liniowych i konwolucyjnych (dodaj [dropout](https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html)). Przetestuj różne optymalizatory i schedulery z biblioteki PyTorch.\n",
    "\n",
    "Dla nauczonych modeli oblicz metryki: MSE, [PSNR](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio), na podstawie których stwierdzisz, który model jest najlepszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b683e72-6c5c-40bc-aa98-ea6d427a3e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
